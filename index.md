---
title: Dr Sarah Mercer
---
<div class="sm_Parent">
    <div class="sm_child1">
        <h1>Geeksfo</h1>
        <center>
            <h1>Left</h1>
        </center>
    </div>
    <div class="sm_child2">
        <h1>rgeeks</h1>
        <center>
            <h1>RIGHT</h1>
        </center>
    </div>
</div>

<!--
<div class="sm_wrap">
  <div class="sm_left_col">
  left
  </div>
  <div class="sm_right_col">
  right
  </div>
</div>
-->

<!--
<table width="100%">
<tr>
<td width="100"><img src="https://drsezzer.github.io/profile_pic.png" /></td>
<td><p>Hi! I'm Sarah, a Principal Researcher at The Alan Turing Institute, working at the intersection of agents and generative AI.</p></td>
</tr>
</table>
-->

<hr>

<p align="center">
<br>
<i class="fa-brands fa-square-github"></i> <a href="https://github.com/drsezzer/drsezzer.github.io">drsezzer</a> |
<i class="fa-brands fa-bluesky"></i> @drsezzer.bsky.social |
<i class="fa-brands fa-square-x-twitter"></i> @FanOfJavi | 
<i class="fa-brands fa-linkedin"></i> <a href="https://www.linkedin.com/in/sarah-mercer-033609273">Sarah Mercer</a> |
<i class="fa-solid fa-envelope"></i> smercer[at]turing.ac.uk
</p>

<hr>

<p>&nbsp;&nbsp;&nbsp;&nbsp; The propensity of LLMs to portray humanlike behaviour fascinates me.  Since the publication of the Willowbrook report, I have continued to explore the ability of generative agents to mimic us... including their ability to maintain believable persona's, their capacity to make human like mistakes, and their (in)ability to get angry!</p>

<p align=center><img src="https://drsezzer.github.io/willowbrook1.png" /></p>

<p>&nbsp;&nbsp;&nbsp;&nbsp; A few people have asked me what a generative agent actually is, how are they implemented and the frameworks I use... </p>

<p>&nbsp;&nbsp;&nbsp;&nbsp; I dont use a framework, as I am keen to get a feeling for what the LLM is able to deliver, without an additional layer of abstraction between me and the LLM.  The key to designing a good persona-agent lies in its initial biography and it's memory retention mechanism. I expand on this more [here](agent-architecture.md)</p>

## Research Publications

### Generative Agents:

* [Welcome to Willowbrook](https://cetas.turing.ac.uk/publications/welcome-willowbrook), The simulated society built by generative agents, December 2023.  <i>Not to be confused with <a href="https://www.technologyreview.com/2024/11/27/1107377/a-minecraft-town-of-ai-characters-made-friends-invented-jobs-and-spread-religion/">Meadowbrook</a>!</i> :thinking:

### Cyber Security:

* [Generative AI in Cyber Security](https://cetas.turing.ac.uk/publications/generative-ai-cybersecurity), Assessing impact on current and future malicious software, June 2024.  <i class="fa-solid fa-file-pdf"></i> [Formal PDF](docs/cetas_briefing_paper_-_evaluating_malicious_generative_ai_capabilities.pdf). <br> <i class="fa-solid fa-pen-ruler"></i> [Final (unedited) Draft](raw_malicious_genai.md)


<p>&nbsp;&nbsp;&nbsp;&nbsp; Alongside my own research looking at the human like capacity of generative agents, I also provide technical expertise to the CETaS team.</p>

### CETaS papers:

* [Evaluating Malicious Generative AI Capabilities](https://cetas.turing.ac.uk/publications/evaluating-malicious-generative-ai-capabilities), Understanding inflection points in risk, July 2024.

* [The Rapid Rise of Generative AI](https://cetas.turing.ac.uk/publications/rapid-rise-generative-ai), Assessing risks to safety and security, December 2023.

* [Securing the UK's Research Eco-system](https://cetas.turing.ac.uk/), coming soon.


## Current Projects:

* Psychometric testing for generative agents.  Is it a good idea to use generative agents as replacement humans in social science?
* Willowbrook baseline configuration; as an evaluation mechanism for new LLM models.
