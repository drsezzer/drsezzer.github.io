<p>Hi, I'm Sarah, a Principal Researcher at The Alan Turing Institute, working at the intersection of agents and generative AI.  Alongside my own research looking at the human like capacity of generative agents, I also provide technical expertise to the CETaS team.</p>

<p align=center><img src="https://drsezzer.github.io/willowbrook1.png" /></p>

<p>The propensity of LLMs to portray humanlike behaviour fascinates me.  Since the publication of the Willowbrook report, I have continued to explore the ability of generative agents to mimic us... including their ability to maintain believable persona's, their capacity to make human like mistakes, and their (in)ability to become annoyed!</p>

<p>A few people have asked me what a generative agent actually is, how are they implemented and the frameworks I use.  I dont use a framework, as I am keen to get a feeling for what the LLM is able to deliver, without an additional layer of abstraction, between me and the LLM.  The key to designing a good persona-agent lies in its initial biography and the organisation/retention of it's memories. I expand on this more [here](agent-architecture.md)</p>

## Research Publications

### Generative Agents:
* [Welcome to Willowbrook](https://cetas.turing.ac.uk/publications/welcome-willowbrook), The simulated society built by generative agents, December 2023.

### Cyber Security:
* [Generative AI in Cyber Security](https://cetas.turing.ac.uk/publications/generative-ai-cybersecurity), Assessing impact on current and future malicious software, June 2024.

### CETaS papers:
* [Evaluating Malicious Generative AI Capabilities](https://cetas.turing.ac.uk/publications/evaluating-malicious-generative-ai-capabilities), Understanding inflection points in risk, July 2024.
* [The Rapid Rise of Generative AI](https://cetas.turing.ac.uk/publications/rapid-rise-generative-ai), Assessing risks to safety and security, December 2023.


