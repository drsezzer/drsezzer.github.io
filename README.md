

<table border=0>
<tr>
    <td width="100">
    <img src="https://drsezzer.github.io/profile_pic.png" />
    </td>
    <td>
        <p>Hi! I'm Sarah, a Principal Researcher at The Alan Turing Institute, working at the intersection of agents and generative AI.  Alongside my own research looking at the human like capacity of generative agents, I also provide technical expertise to the CETaS team.</p>
    </td>
</tr>
</table>

<div align="center">
<i class="fa-brands fa-bluesky"></i> 

@drsezzer.bsky.social |

<i class="fa-brands fa-linkedin"></i> 

[sarah-mercer](https://www.linkedin.com/in/sarah-mercer-033609273) |

<i class="fa-brands fa-square-github"></i> drsezzer |

</div>

<p>&nbsp;&nbsp;&nbsp;&nbsp; The propensity of LLMs to portray humanlike behaviour fascinates me.  Since the publication of the Willowbrook report, I have continued to explore the ability of generative agents to mimic us... including their ability to maintain believable persona's, their capacity to make human like mistakes, and their (in)ability to become annoyed!</p>


<p align=center><img src="https://drsezzer.github.io/willowbrook1.png" /></p>


<p>&nbsp;&nbsp;&nbsp;&nbsp; A few people have asked me what a generative agent actually is, how are they implemented and the frameworks I use... </p>
<p>&nbsp;&nbsp;&nbsp;&nbsp; I dont use a framework, as I am keen to get a feeling for what the LLM is able to deliver, without an additional layer of abstraction between me and the LLM.  The key to designing a good persona-agent lies in its initial biography and it's memory retention mechanism. I expand on this more [here](agent-architecture.md)</p>

## Research Publications

### Generative Agents:
* [Welcome to Willowbrook](https://cetas.turing.ac.uk/publications/welcome-willowbrook), The simulated society built by generative agents, December 2023.

### Cyber Security:
* [Generative AI in Cyber Security](https://cetas.turing.ac.uk/publications/generative-ai-cybersecurity), Assessing impact on current and future malicious software, June 2024.  [Formal PDF](docs/cetas_briefing_paper_-_evaluating_malicious_generative_ai_capabilities.pdf), [Final (unedited) Draft](raw_malicious_genai.md)

### CETaS papers:
* [Evaluating Malicious Generative AI Capabilities](https://cetas.turing.ac.uk/publications/evaluating-malicious-generative-ai-capabilities), Understanding inflection points in risk, July 2024.
* [The Rapid Rise of Generative AI](https://cetas.turing.ac.uk/publications/rapid-rise-generative-ai), Assessing risks to safety and security, December 2023.
* [Securing the UK's Research Eco-system](https://cetas.turing.ac.uk/), coming soon.


